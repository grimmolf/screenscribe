"""Output generation module for screenscribe."""

from pathlib import Path
from typing import List
from datetime import datetime
import json
import logging

from .models import ProcessingResult

logger = logging.getLogger(__name__)


class OutputGenerator:
    """Generates Markdown or HTML output from processing results."""
    
    def __init__(self, format: str = "markdown"):
        """
        Initialize output generator.
        
        Args:
            format: Output format ("markdown" or "html")
        """
        self.format = format
        logger.info(f"OutputGenerator initialized with format: {format}")
    
    def generate(self, result: ProcessingResult, output_dir: Path) -> Path:
        """Generate final output file."""
        logger.info(f"Generating {self.format} output...")
        
        if self.format == "markdown":
            return self._generate_markdown(result, output_dir)
        else:
            return self._generate_html(result, output_dir)
    
    def _generate_markdown(self, result: ProcessingResult, output_dir: Path) -> Path:
        """Generate Markdown output."""
        output_file = output_dir / "notes.md"
        
        logger.info(f"Generating Markdown output: {output_file}")
        
        # Build content
        lines = []
        
        # Header
        lines.append(f"# {result.video_metadata.title}")
        lines.append("")
        lines.append(f"**Duration:** {result.video_metadata.duration_str}")
        lines.append(f"**Processed:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"**Resolution:** {result.video_metadata.width}x{result.video_metadata.height}")
        lines.append(f"**FPS:** {result.video_metadata.fps:.2f}")
        
        if result.video_metadata.youtube_url:
            lines.append(f"**Source:** [{result.video_metadata.youtube_url}]({result.video_metadata.youtube_url})")
        
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # Processing summary
        lines.append("## Processing Summary")
        lines.append("")
        lines.append(f"- **Frames extracted:** {len(result.frames)}")
        lines.append(f"- **Transcript segments:** {len(result.transcript_segments)}")
        lines.append(f"- **Sampling mode:** {result.processing_options.sampling_mode}")
        lines.append(f"- **Whisper model:** {result.processing_options.whisper_model}")
        lines.append(f"- **Processing time:** {result.processing_time:.1f}s")
        lines.append("")
        
        # Timeline
        lines.append("## Timeline")
        lines.append("")
        
        # Process each synthesis result
        for i, synthesis in enumerate(result.synthesis_results):
            if i >= len(result.aligned_content):
                logger.warning(f"Synthesis result {i} has no corresponding aligned content")
                continue
                
            aligned = result.aligned_content[i]
            
            # Section header with timestamp
            lines.append(f"### {aligned.frame.timestamp_str} ({synthesis.frame_timestamp:.1f}s)")
            lines.append("")
            
            # Thumbnail with link to full frame
            try:
                rel_thumb = aligned.frame.thumbnail_path.relative_to(output_dir)
                rel_frame = aligned.frame.frame_path.relative_to(output_dir)
                
                lines.append(f"[![Frame]({rel_thumb})]({rel_frame})")
                lines.append("")
            except ValueError as e:
                logger.warning(f"Failed to create relative paths for frame {i}: {e}")
                lines.append(f"*Frame image: {aligned.frame.thumbnail_path.name}*")
                lines.append("")
            
            # Transcript
            transcript = aligned.get_transcript_text()
            if transcript:
                lines.append(f"**Transcript:** \"{transcript}\"")
                lines.append("")
            
            # Synthesis
            if synthesis.summary:
                lines.append(f"**Summary:** {synthesis.summary}")
                lines.append("")
            
            # Visual description if available
            if synthesis.visual_description:
                lines.append(f"**Visual:** {synthesis.visual_description}")
                lines.append("")
            
            # Key points
            if synthesis.key_points:
                lines.append("**Key Points:**")
                for point in synthesis.key_points:
                    lines.append(f"- {point}")
                lines.append("")
            
            lines.append("---")
            lines.append("")
        
        # Footer
        lines.append(f"*Generated by screenscribe v1.0.0 in {result.processing_time:.1f}s*")
        
        # Write file
        content = "\n".join(lines)
        output_file.write_text(content, encoding='utf-8')
        
        # Also save raw JSON for reprocessing
        json_file = output_dir / "processing_result.json"
        result.save(json_file)
        
        logger.info(f"Markdown output written to: {output_file}")
        return output_file
    
    def _generate_html(self, result: ProcessingResult, output_dir: Path) -> Path:
        """Generate HTML output with embedded styles."""
        output_file = output_dir / "notes.html"
        
        logger.info(f"Generating HTML output: {output_file}")
        
        # HTML header with embedded styles
        html = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{result.video_metadata.title} - Notes</title>
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }}
        .header {{
            border-bottom: 2px solid #eee;
            padding-bottom: 20px;
            margin-bottom: 30px;
        }}
        .metadata {{
            background: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
        }}
        .frame-section {{
            margin: 2em 0;
            border-bottom: 1px solid #eee;
            padding-bottom: 2em;
        }}
        .timestamp {{
            color: #0066cc;
            font-weight: bold;
            font-size: 1.2em;
        }}
        .thumbnail {{
            max-width: 320px;
            border: 1px solid #ddd;
            cursor: pointer;
            margin: 10px 0;
            border-radius: 5px;
        }}
        .thumbnail:hover {{
            border-color: #0066cc;
        }}
        .transcript {{
            background: #f5f5f5;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
            border-left: 4px solid #0066cc;
            font-style: italic;
        }}
        .summary {{
            font-weight: 500;
            margin: 10px 0;
        }}
        .key-points {{
            margin-left: 20px;
        }}
        .key-points li {{
            margin: 5px 0;
        }}
        .visual-desc {{
            color: #666;
            font-style: italic;
            margin: 10px 0;
        }}
        .footer {{
            text-align: center;
            color: #666;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #eee;
        }}
        .processing-info {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 10px;
            margin: 15px 0;
        }}
        .processing-info div {{
            background: #e9ecef;
            padding: 10px;
            border-radius: 3px;
        }}
    </style>
</head>
<body>
    <div class="header">
        <h1>{result.video_metadata.title}</h1>
        <div class="metadata">
            <strong>Duration:</strong> {result.video_metadata.duration_str}<br>
            <strong>Processed:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}<br>
            <strong>Resolution:</strong> {result.video_metadata.width}x{result.video_metadata.height}<br>
            <strong>FPS:</strong> {result.video_metadata.fps:.2f}
"""
        
        if result.video_metadata.youtube_url:
            html += f'            <br><strong>Source:</strong> <a href="{result.video_metadata.youtube_url}" target="_blank">{result.video_metadata.youtube_url}</a>'
        
        html += """
        </div>
    </div>
    
    <div class="processing-summary">
        <h2>Processing Summary</h2>
        <div class="processing-info">
"""
        
        html += f"""
            <div><strong>Frames:</strong> {len(result.frames)}</div>
            <div><strong>Segments:</strong> {len(result.transcript_segments)}</div>
            <div><strong>Sampling:</strong> {result.processing_options.sampling_mode}</div>
            <div><strong>Model:</strong> {result.processing_options.whisper_model}</div>
            <div><strong>Time:</strong> {result.processing_time:.1f}s</div>
        </div>
    </div>
    
    <h2>Timeline</h2>
"""
        
        # Add content sections
        for i, synthesis in enumerate(result.synthesis_results):
            if i >= len(result.aligned_content):
                continue
                
            aligned = result.aligned_content[i]
            
            # Make paths relative for portability
            try:
                rel_thumb = aligned.frame.thumbnail_path.relative_to(output_dir)
                rel_frame = aligned.frame.frame_path.relative_to(output_dir)
            except ValueError:
                rel_thumb = aligned.frame.thumbnail_path.name
                rel_frame = aligned.frame.frame_path.name
            
            html += f"""
    <div class="frame-section">
        <h3><span class="timestamp">{aligned.frame.timestamp_str}</span> ({synthesis.frame_timestamp:.1f}s)</h3>
        <a href="{rel_frame}" target="_blank">
            <img src="{rel_thumb}" class="thumbnail" alt="Frame at {aligned.frame.timestamp_str}">
        </a>
"""
            
            transcript = aligned.get_transcript_text()
            if transcript:
                html += f"""
        <div class="transcript">
            <strong>Transcript:</strong> "{transcript}"
        </div>
"""
            
            if synthesis.summary:
                html += f'        <div class="summary"><strong>Summary:</strong> {synthesis.summary}</div>\n'
            
            if synthesis.visual_description:
                html += f'        <div class="visual-desc"><strong>Visual:</strong> {synthesis.visual_description}</div>\n'
            
            if synthesis.key_points:
                html += '        <div class="key-points"><strong>Key Points:</strong>\n'
                html += '            <ul>\n'
                for point in synthesis.key_points:
                    html += f'                <li>{point}</li>\n'
                html += '            </ul>\n'
                html += '        </div>\n'
            
            html += '    </div>\n'
        
        html += f"""
    <div class="footer">
        <p><em>Generated by screenscribe v1.0.0 in {result.processing_time:.1f}s</em></p>
    </div>
</body>
</html>"""
        
        # Write file
        output_file.write_text(html, encoding='utf-8')
        
        # Also save raw JSON
        json_file = output_dir / "processing_result.json"
        result.save(json_file)
        
        logger.info(f"HTML output written to: {output_file}")
        return output_file